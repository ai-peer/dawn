{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "5b8164df_9df86b74",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000262
      },
      "writtenOn": "2022-11-23T21:38:02Z",
      "side": 1,
      "message": "@Jiawei, thank you for the add. I have some thoughts of my own.\n\nFirst, DirectX already has a way for applications to pick an adapter with a GPU preference by using IDXGIFactory6::EnumAdapterByGpuPreference. For implementing WebGPU\u0027s \"powerPreference\" attribute, we should utilize this DXGI API and pass the PREFERENCE_HIGH_PERFORMANCE enum value. If this extension is meant as a replacement for EnumAdapterByGpuPreference or as a way to pick on behalf of Chromium under the covers, then we should not be using it. Chromium should be in control over what adapter gets used for rendering.\n\n\nSecond, if this extension impacts power management, it’s very questionable for browser to override this behavior in a default context. In this CL, I see that the \"maximum performance\" adapter is always enumerated in DiscoverAdapters so I\u0027m not clear what your intent is. Tests should run in the same, default configuration that end users run. \n\nThere’s existing Windows infrastructure around different power profiles that users and IT departments can configure, different profiles for plugged in vs. battery power, going into power saving mode when battery is low, etc. We shouldn\u0027t circumvent this. Enabling this for default context means we\u0027re trading one bug, low FPS, for another bug, excessive battery consumption. The former problem is a more tractable to tackle with tools and analysis than the latter. \n\n\nThird, if this extension is meant as a way for the Intel adapter to be better at benchmarks, this seems like something better solved on the Intel side. Why can\u0027t the driver/hardware work great with WebGPU without having to be told to do so?",
      "revId": "fb87a9e27b0ba48b65abaf9c5eecffe4cb0280f0",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c48dce86_26258f94",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2022-11-24T06:03:35Z",
      "side": 1,
      "message": "Hi Rafael, thanks for your comments.\n\n\u003e First, DirectX already has a way for applications to pick an adapter with a GPU preference by using IDXGIFactory6::EnumAdapterByGpuPreference. For implementing WebGPU\u0027s \"powerPreference\" attribute, we should utilize this DXGI API and pass the PREFERENCE_HIGH_PERFORMANCE enum value. If this extension is meant as a replacement for EnumAdapterByGpuPreference or as a way to pick on behalf of Chromium under the covers, then we should not be using it. Chromium should be in control over what adapter gets used for rendering.\n\nIn this patch we are not trying to choose different DXGI Adapters. What we intend to do is providing a way to create a logical WebGPU Adapter on an Intel GPU with \"High-Performance\" power preference, and at the same time there is also another WebGPU Adapter on the same Intel GPU with \"low-power\" power preference for Chromium to choose.\n\n\u003e Second, if this extension impacts power management, it’s very questionable for browser to override this behavior in a default context. In this CL, I see that the \"maximum performance\" adapter is always enumerated in DiscoverAdapters so I\u0027m not clear what your intent is. Tests should run in the same, default configuration that end users run.\n\nOh I did this just because of the convenience to test in my side. I\u0027ve corrected it in the latest patch set. Sorry for the misleading.\n\n\n\u003e There’s existing Windows infrastructure around different power profiles that users and IT departments can configure, different profiles for plugged in vs. battery power, going into power saving mode when battery is low, etc. We shouldn\u0027t circumvent this.\n\nIt\u0027s up to Chromium to decide to choose the \"high-performance\" Intel GPU or not.\n\nThe \"MAX_PERFORMANCE\" Intel GPU should only be chosen only when the WebGPU application is requesting a \"high-performance\" WebGPU adapter. If the WebGPU application cares power saving most, it should request a \"low-power\" adapter. Otherwise, if the WebGPU application is requesting a \"max-performance\" adapter, then according to the WebGPU SPEC, it indicates a request to prioritize performance over power consumption, so in this situation we have the responsibility to provide an Intel WebGPU adapter that can run WebGPU applications with the maximum performance.\n\nFor example,\n1. We can completely ignore the \"high-performance\" Intel GPU when the device is not plugged in.\n2. We can completely ignore the \"high-performance\" Intel GPU when WebGPU application is requesting a \"low-power\" adapter.\n3. When the device is plugged in, the system is in \"high performance\" battery mode, and the WebGPU application is requesting a \"high-performance\" adapter, we should return the \"high-performance\" Intel GPU to pursue the best performance.\n\nFurthermore, the Intel Throttle Policy extension just provides us a hint to tell the Intel GPU to execute the commands in MAX_PERFORMANCE way. We have seen the hint being ignored in many situations.\n\n\u003e Enabling this for default context means we\u0027re trading one bug, low FPS, for another bug, excessive battery consumption. The former problem is a more tractable to tackle with tools and analysis than the latter.\n\nThe Intel Throttle Policy extension is treated as part of Intel Windows driver and is being well tested in Intel driver CI, so the quality and compatibility of this feature can be guaranteed by Intel.\n\n\u003e Third, if this extension is meant as a way for the Intel adapter to be better at benchmarks, this seems like something better solved on the Intel side. Why can\u0027t the driver/hardware work great with WebGPU without having to be told to do so?\n\nThis extension is not mainly meant as a way for benchmarking. We pursue having it in Dawn because it can really benefit many real use-cases. (e.g. running TFJS models with image element as input)\nWe think this extension is useful in Dawn because we find with this explicit hint the current Intel GPU will do much better in performance boosting.",
      "parentUuid": "5b8164df_9df86b74",
      "revId": "fb87a9e27b0ba48b65abaf9c5eecffe4cb0280f0",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    }
  ]
}