{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "d5c42034_05bd8f0b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "I\u0027m sorry but the more I read this CL and surrounding code, the more concerns I have with the current approach that we are using to handle these classes of problems (async pipeline creation, but also its interactions with pipeline deduplication, pipeline caching, etc).\n\nThe basic issue is that concurrency is amazingly hard to get right and any issues in concurrent code will lead to bugs that are extremely difficult to reproduce. Right now in Dawn, and even more with this CL, there is a lot of code in a bunch of places that deals with parts of pipeline creation and interact in subtle ways.\n\nInstead we should have objects and concept with clear interfaces and spelt-out guarantees in terms of concurrency that hide the synchronization of caches, task queues, etc behind a safe interface. Then device.createComputePipeline[Async] would just call this \"ComputePipelineFactory\" (yes I know that starts to look like enterprise code) that deals with all the difficult details in one place. Then the backends either implement an interface or a subclass of that factory for just the parts needed. Both the backend\u0027s interface and the factory can then be tested independently with stress tests for concurrency cases under TSAN.\n\nThe thing is, doing concurrency with the amount of respect needed for the problem will be a lot of work. It will mean doing large refactors in Dawn, like introducing the \"CallbackQueue\" on the device, probably some concept of ConstRef\u003cT\u003e, deciding on conventions for what is threadsafe and what isn\u0027t, etc. I don\u0027t think any of us will have time to spend on that before the Origin Trial.\n\nHowever I understand that TF.js is very interested in actual async pipeline compilation too. So in the meantime, I think we can have a toggle off by default like concurrent_create_pipeline_async that controls if we actually use WorkerTasks or not. Then we can probably end with landing an iteration of this CL.",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a76b6c2d_091bd22c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2021-04-19T02:59:11Z",
      "side": 1,
      "message": "Sorry to hear about that. :-(\n\nFor myself, I really don\u0027t want to put any questionable code into Dawn, even if I am agreed to first have it behind a flag.\n\n\nHere I just want to have another try to save this CL:\n\nShall we just make the parts asynchronously that we have full confidence in their thread-safety? I think the most time-consuming parts should be (use D3D12 backend as an example) as below, which I think are undoubtedly thread-safe:\n1. translate from WGSL to HLSL with Tint (I think it should be thread-safe?)\n2. compile HLSL with dxcompiler-\u003eD3DCompile()\n3. create D3D12 render pipeline\n\nThe steps above are all in ComputePipeline::Create(), so it seems we can just make this function called asynchronously. Something like below:\n1. Call ComputePipeline::Create() to create a compute pipeline object on PostWorkerTask()\n2. In the sub-thread, the result of ComputePipeline::Create() will be put into a concurrent queue that contains all the compute pipeline objects created asynchronously and the related callbacks or error messages\n3. In DeviceD3D12.tick() called in main thread:\n(1) check the concurrent queue that contains the compute pipelines created in step 2 if their creations are completed or not.\n(2) put the newly-created compute pipelines into DeviceBase::Cache and call the callbacks\n\nFollowing the steps above, I think\n1. We don\u0027t need to care about the thread-safety of DeviceBase::Cache, ExecutionSerial, and CreatePipelineResultTracker as they are always called in the main thread.\n\n2. We just need to implement the concurrent queue (to store the compute pipelines in creation) and ensure the PersistentCache (to be used as the HLSL shader cache) be thread-safe as they are the only two global resources that are touched in this process.\n\nI will try to write a draft CL and a design doc to show more details with you before our next meeting.",
      "parentUuid": "d5c42034_05bd8f0b",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "edb269e1_99a9f28e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2021-04-20T12:34:25Z",
      "side": 1,
      "message": "Hi Corentin, in the latest patch set I just put ComputePipelineD3D12::Initialize() into PostWorkerTask, so now we don\u0027t need to handle the thread-safety of the front-end pipeline object cache, CreatePipelineAsyncResultTracker (the \"callback queue\") and serials. Now there are only two places that need to be changed to be thread-safe:\n- GetOrCreate[Dxc|Fxc]Compilers\n- Persistent Cache\n\nPTAL, thanks!",
      "parentUuid": "a76b6c2d_091bd22c",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f8a16091_0f6e805a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-20T18:18:30Z",
      "side": 1,
      "message": "I think this is much better but still a bit scary. Austin WDYT? Overall I think we could land this as-is (with some stress test maybe?) and iterate on it to find the correct abstraction for the medium-term (until v1 is out).",
      "parentUuid": "edb269e1_99a9f28e",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bcb5dddc_8223294f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2021-04-21T06:43:26Z",
      "side": 1,
      "message": "It looks ok, and we can make progress on async pipeline creation before other improvements to the abstraction in Dawn. I do think it\u0027d be good to see the callback queue and perhaps a more general way to handle tasks sooner than later. The number of things that happen inside Tick() keeps growing, and for every type of callback we have a new Tracker class to manage it.\n\nI think we should clearly comment on the various functions in this CL about what thread (worker / non-worker) we expect them to be called on. Right now I think it\u0027s prone to people adding / changing functionality that accidentally breaks thread-safety.",
      "parentUuid": "f8a16091_0f6e805a",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "40bfc422_cabd02c1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2021-04-23T08:44:17Z",
      "side": 1,
      "message": "Hi Corentin and Austin, I\u0027ve just filed the issue (dawn:769) to implement CallbackQueue and assigned myself as the owner.\n\nPTAL, thanks!",
      "parentUuid": "bcb5dddc_8223294f",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "26349a42_c00f252e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2021-04-27T05:13:30Z",
      "side": 1,
      "message": "Thanks - I do think we can probably land the async pipeline work first and implement the CallbackQueue after. Either way is ok with me.",
      "parentUuid": "40bfc422_cabd02c1",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c4f8c17a_492fbbab",
        "filename": "src/dawn_native/Device.cpp",
        "patchSetId": 7
      },
      "lineNbr": 68,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "This may happen to work with std::unordered_map (because it does extra allocations), but I have strong concerns that the iterators might become invalidated when other threads are doing operations on the cache at the same time.\n\nWhen doing concurrent primitives like this cache, we should prefer to define safe interfaces that completely prevents any data race possible. Here we could do something like:\n\n  Ref\u003cComputePipeline\u003e Find(const ComputePipeline* blueprint);\n  Ref\u003cComputePipeline\u003e AddOrGet(Ref\u003cComputePipeline\u003e\u0026\u0026 obj);\n  void Remove(const ComputePipeline* obj);",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6d30af7c_af036be1",
        "filename": "src/dawn_native/Device.cpp",
        "patchSetId": 7
      },
      "lineNbr": 161,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "nit: mCreatePipelineAsyncResultTracker instead of mCreatePipelineAsynResultTracker",
      "range": {
        "startLine": 161,
        "startChar": 8,
        "endLine": 161,
        "endChar": 40
      },
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7130a490_d4405428",
        "filename": "src/dawn_native/Device.h",
        "patchSetId": 7
      },
      "lineNbr": 19,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "ditto",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8988f6a1_1095da4d",
        "filename": "src/dawn_native/Device.h",
        "patchSetId": 7
      },
      "lineNbr": 29,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "nit: Could forward declarations work instead of including the file? This would help avoid including DawnPlatform.h almost everywhere.",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e47db70b_73a1a272",
        "filename": "src/dawn_native/Device.h",
        "patchSetId": 7
      },
      "lineNbr": 94,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "With the atomic, this could stay const.",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "73b2885c_24d129a1",
        "filename": "src/dawn_native/Device.h",
        "patchSetId": 7
      },
      "lineNbr": 407,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "This should be possible to do by wrapping std::atomic\u003cuint64_t\u003e and a compare_exchange_weak in a loop (that will be executed once). Also it\u0027s a bit weird to declare a class inline like this.",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6292eebb_aebbd95c",
        "filename": "src/dawn_native/PersistentCache.h",
        "patchSetId": 7
      },
      "lineNbr": 60,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-16T15:48:32Z",
      "side": 1,
      "message": "This locks the cache for the duration of createFn too. We could instead lock just while we call LoadData and StoreData. This could lead to some redundant computations but is better than serializing all shader compilations.\n\nPlease also add a class level comment about concurrency otherwise we\u0027ll quickly forget what has been made concurrent and what hasn\u0027t.",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b7ddb668_cfeaf672",
        "filename": "src/dawn_native/PersistentCache.h",
        "patchSetId": 7
      },
      "lineNbr": 60,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2021-04-20T18:18:30Z",
      "side": 1,
      "message": "Changes in mutexing looks good. I think it would still be nice to have a comment about concurrency at the top of the class.",
      "parentUuid": "6292eebb_aebbd95c",
      "revId": "c2cdbc5271bb1361170963b9b5a6f7be8edd7c90",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    }
  ]
}