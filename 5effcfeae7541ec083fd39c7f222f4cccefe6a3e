{
  "comments": [
    {
      "key": {
        "uuid": "58b4df5a_c5bc7ee4",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-24T01:21:08Z",
      "side": 1,
      "message": "PTAL!",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "a12af324_52aef752",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2020-07-24T18:28:09Z",
      "side": 1,
      "message": "Don\u0027t we need to inform AllocateAndSwitch at least how large we want the new heap? Otherwise it\u0027ll blindly double in size which still may not be large enough for PopulateViews.\n\nWe call AllocateAndSwitch here https://source.chromium.org/chromium/chromium/src/+/master:third_party/dawn/src/dawn_native/d3d12/CommandBufferD3D12.cpp;l\u003d212?q\u003dAllocateAndSwitchShaderVisibleHeap\n\nand then here https://source.chromium.org/chromium/chromium/src/+/master:third_party/dawn/src/dawn_native/d3d12/CommandBufferD3D12.cpp;l\u003d214?q\u003dAllocateAndSwitchShaderVisibleHeap\n\nwe ASSERT that the heap was actually large enough to satisfy PopulateViews\n\n",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6e43a031_814014ac",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-24T18:56:45Z",
      "side": 1,
      "message": "I found it easiest to keep the initial (min) heap size large enough to satisfy the largest request, so no doubling occurs at first (or ASSERT). This was set for (sampler\u003d256, view\u003d4k), well above the limits but I left a TODO to tweak that, if needed.",
      "parentUuid": "a12af324_52aef752",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "13085f32_fa04ec0c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2020-07-24T19:08:18Z",
      "side": 1,
      "message": "Ah okay I see. Please add some comments about this invariant and also static_assert the min sizes w.r.t kMaxBindingsPerPipelineLayout and the computed max total descriptor count per pipeline layout per heap.\n\nIf we\u0027re doing this dynamic sizing though, is there a reason to have the minimum satisfy the largest possible request? Or, are the current minimums small enough to be insignificant? It seems reasonable to accumulate the required descriptor counts for the pipeline layout.",
      "parentUuid": "6e43a031_814014ac",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1a97a229_7617ce42",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-24T19:50:41Z",
      "side": 1,
      "message": "Will do.\n\nYea, it\u0027s the latter but the current minimums are really only the maximums which is mostly a problem with the view heaps (max size \u003d\u003d 1 million+). So, picking a muuuuch smaller size (4k vs 1M) but big enough compared to Dawn\u0027s limits fixes our main memory issue.\n\nIf we use a min size that\u0027s sized exactly to the pipeline layout, heavy users will flush the pipeline a lot more as they ramp-up and we might find it preferable to minimize the growth phase by picking a larger min size. I am more concerned there because Dawn requires dynamic copies + uncached views.",
      "parentUuid": "13085f32_fa04ec0c",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "018b2e09_cf9b01de",
        "filename": "src/dawn_native/d3d12/ShaderVisibleDescriptorAllocatorD3D12.cpp",
        "patchSetId": 3
      },
      "lineNbr": 86,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-27T08:36:11Z",
      "side": 1,
      "message": "This feels like a hack, why not have a member variable on ShaderVisibleDescriptorAllocator instead?",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "25408ea1_8165bc5a",
        "filename": "src/dawn_native/d3d12/ShaderVisibleDescriptorAllocatorD3D12.cpp",
        "patchSetId": 3
      },
      "lineNbr": 86,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-27T19:35:46Z",
      "side": 1,
      "message": "I noticed we already store the same size on |ShaderVisibleDescriptorHeap| and didn\u0027t want to  unnecessarily duplicate/track another. Maybe we can pass |mHeap| to AllocateAndSwitchShaderVisibleHeap to make this more obvious?",
      "parentUuid": "018b2e09_cf9b01de",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c259b281_f89ff4a9",
        "filename": "src/dawn_native/d3d12/ShaderVisibleDescriptorAllocatorD3D12.cpp",
        "patchSetId": 3
      },
      "lineNbr": 144,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-27T08:36:11Z",
      "side": 1,
      "message": "This is going to grow the heap in powers of twos until it reaches the maxDescriptorCount, even for a light user.\n\nInstead how about doing the following: keep track of how many descriptors are in flight at each instant, and divide this number by two (or 4) to get an estimate of how many descriptors we need \"per frame\". Then allocate a ShaderVisibleDescriptorHeap with the correct size (or reuse the existing one).\n\nAlso the logic that does the estimate should be split in a different function, so this one only care about reusing vs. allocating and the heuristic is boxed in its own part of the code.",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e37349cb_f465a4d0",
        "filename": "src/dawn_native/d3d12/ShaderVisibleDescriptorAllocatorD3D12.cpp",
        "patchSetId": 3
      },
      "lineNbr": 144,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-27T19:35:46Z",
      "side": 1,
      "message": "\u003e This is going to grow the heap in powers of twos until it reaches the maxDescriptorCount, even for a light user.\n\nA light user, by definition, is one that will never reach maxDescriptorCount. It can use the min size _indefinitely_.\n\n\u003e Then allocate a ShaderVisibleDescriptorHeap with the correct size (or reuse the existing one).\n\nI rarely (if ever) see more than one or two frames in-flight. If it proves too small, we incur expensive pipeline flushes + heap creation overhead. If you are certain that more accuracy is required, I\u0027ll need help to understand that scenario. Otherwise, a min heap + 2x growth should ensure there is always enough room for frames in-flight and comes with no additional tracking. WDYT?",
      "parentUuid": "c259b281_f89ff4a9",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "29cdbfb8_8e5a0c0f",
        "filename": "src/tests/white_box/D3D12DescriptorHeapTests.cpp",
        "patchSetId": 3
      },
      "lineNbr": 261,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-27T08:36:11Z",
      "side": 1,
      "message": "Can we have a separate fixture for tests that count the number of switches so we always run them with the toggle and don\u0027t need this DAWN_SKIP_TEST_IF?",
      "revId": "5effcfeae7541ec083fd39c7f222f4cccefe6a3e",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    }
  ]
}