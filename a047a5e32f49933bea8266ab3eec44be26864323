{
  "comments": [
    {
      "key": {
        "uuid": "2bb21984_5e4efb59",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2020-07-14T04:22:25Z",
      "side": 1,
      "message": "PTAL, thanks!",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "2e5401c2_e6bfe54b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-14T12:32:58Z",
      "side": 1,
      "message": "LGTM with the caveat that it needs to be updated for MapAsync.",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ca75ff35_92125070",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2020-07-14T17:54:00Z",
      "side": 1,
      "message": "no additional comments",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "22df238c_340e7fa3",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-14T21:09:19Z",
      "side": 1,
      "message": "Left some thoughts, LGTM. Thanks, Jiawei.",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "194c5fa8_1665943f",
        "filename": "src/dawn_native/vulkan/BufferVk.cpp",
        "patchSetId": 2
      },
      "lineNbr": 250,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-14T12:32:58Z",
      "side": 1,
      "message": "What do you think of doing the lazy initialization on the CPU in the frontend instead? It is possible to do for mapped buffers (and mapped at creation ones) because they are CPU accessible.\n\nIf we did it this way it would be in OnMapCommandSerialFinished I think. And in MapAtCreation().\n\nI\u0027m not sure which is best, because the CPU should be less efficient than the GPU to clear buffers, but at the same time Enqueing work on the GPU to lazy-clear buffers means more barriers. Maybe it\u0027s fine as-is.\n\nAlso note that this should be rebased on top of https://dawn-review.googlesource.com/c/dawn/+/24260 that adds the MapAsyncImpl virtual method. (and we\u0027ll need the tests updated to also test MapAsync, or only MapAsync).",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "72750627_60f59810",
        "filename": "src/dawn_native/vulkan/BufferVk.cpp",
        "patchSetId": 2
      },
      "lineNbr": 250,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-14T21:09:19Z",
      "side": 1,
      "message": "The fastest method I know of uses optimized clear (via ClearRTV). This dirties the pages in MMU w/o needing to write anything by CPU or firing-up the copy/3D engine on GPU. But it only works when clearing to some trivial 1-bit value (but that\u0027s what ClearBuffer here does).\n\nIf it\u0027s between the slowest options (GPU copy vs CPU), then I\u0027d wager touching smaller buffers via CPU could be faster per Corentin\u0027s rationale.",
      "parentUuid": "194c5fa8_1665943f",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f7963ab4_ce3c3d83",
        "filename": "src/dawn_native/vulkan/BufferVk.cpp",
        "patchSetId": 2
      },
      "lineNbr": 250,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-15T09:15:14Z",
      "side": 1,
      "message": "We discussed this briefly in the meeting we had with Jiawei today, and any implementation works for now because we are in the \"correctness\" phase of this feature. I think it is ok as-is because it\u0027s not very complex and allows for optimizations like the RTV one you suggested.",
      "parentUuid": "72750627_60f59810",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0fe80afc_90d02479",
        "filename": "src/dawn_native/vulkan/BufferVk.cpp",
        "patchSetId": 2
      },
      "lineNbr": 250,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2020-07-16T07:57:53Z",
      "side": 1,
      "message": "\u003e What do you think of doing the lazy initialization on the CPU in the frontend instead? It is possible to do for mapped buffers (and mapped at creation ones) because they are CPU accessible.\n\nI think currently we only need to consider this on Vulkan (and maybe OpenGL) backend now.\n- On D3D12, we can only clear the writable mapped buffer on CPU side because it is created on UPLOAD heap.\n- On Metal we can always use function \"fillBuffer\" without any barriers.\n- On OpenGL currently we are clearing a buffer with BufferSubData(), where we need to create a large array on the CPU side and upload it to the GPU. This can be optimized.\n- On Vulkan currently we are calling FillBuffer() with a barrier before and a barrier after. I think it\u0027s worth writing a performance test to see if it is faster to clear buffer on CPU or GPU side. But I think maybe it\u0027s better for us to do it in another CL, what do you think?\n\n\u003e Also note that this should be rebased on top of https://dawn-review.googlesource.com/c/dawn/+/24260 that adds the MapAsyncImpl virtual method. (and we\u0027ll need the tests updated to also test MapAsync, or only MapAsync).\n\nIn the latest patch set I don\u0027t add the lazy initialization path for MapReadAsync and MapWriteAsync because they are deprecated.",
      "parentUuid": "f7963ab4_ce3c3d83",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "db1b309b_0c958126",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-14T12:32:58Z",
      "side": 1,
      "message": "All of this could be replaced by:\n\n  void MapReadAsyncAndWait(buffer) {\n    bool done \u003d fasle;\n    buffer.MapReadAsync([](WGPUBufferMapAsyncStatus status, const void*, uint64_t, void* userdata) {\n           ASSERT_EQ(WGPUBufferMapAsyncStatus_Success, status);\n           *static_cast\u003cbool*\u003e(userdata) \u003d true;\n        }, \u0026done)\n\n     while !done {WaitABit();}\n  }\n\nThen the pointer can be retrieved with buffer.Get[Const]MappedRange(); (this is the new mapping mechanism).",
      "range": {
        "startLine": 40,
        "startChar": 0,
        "endLine": 58,
        "endChar": 5
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ff789d3c_60e490a2",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 1000268
      },
      "writtenOn": "2020-07-14T21:09:19Z",
      "side": 1,
      "message": "(Unrelated note) WaitABit spin-waits when a device error occurs in-flight and locks up my console on any failure. We should probably exit early given how prevalent this pattern is for testing.",
      "parentUuid": "db1b309b_0c958126",
      "range": {
        "startLine": 40,
        "startChar": 0,
        "endLine": 58,
        "endChar": 5
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6454ff6c_5346552f",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-15T09:15:14Z",
      "side": 1,
      "message": "I noticed that too, but it\u0027s usually because if an error in my WIP CL so it\u0027s ok. Do you know what WaitABit never stops? The callback should be called in finite time.",
      "parentUuid": "ff789d3c_60e490a2",
      "range": {
        "startLine": 40,
        "startChar": 0,
        "endLine": 58,
        "endChar": 5
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a69c06d3_4d501b93",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2020-07-16T07:57:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "6454ff6c_5346552f",
      "range": {
        "startLine": 40,
        "startChar": 0,
        "endLine": 58,
        "endChar": 5
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f14b9c13_6c26cdb8",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-14T12:32:58Z",
      "side": 1,
      "message": "These would become unused and could be removed.",
      "range": {
        "startLine": 80,
        "startChar": 0,
        "endLine": 88,
        "endChar": 40
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "95705da9_2c785360",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 88,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2020-07-16T07:57:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "f14b9c13_6c26cdb8",
      "range": {
        "startLine": 80,
        "startChar": 0,
        "endLine": 88,
        "endChar": 40
      },
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6774babe_03fb0bcc",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 343,
      "author": {
        "id": 1000002
      },
      "writtenOn": "2020-07-14T12:32:58Z",
      "side": 1,
      "message": "I don\u0027t think we need to check with writing values, and could just check that the CPU-side pointer is filled with zeros (the CPU side gets uploaded to the GPU on Unmap anyway).",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4eacff71_a1050a3f",
        "filename": "src/tests/end2end/BufferZeroInitTests.cpp",
        "patchSetId": 2
      },
      "lineNbr": 343,
      "author": {
        "id": 1000019
      },
      "writtenOn": "2020-07-16T07:57:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "6774babe_03fb0bcc",
      "revId": "a047a5e32f49933bea8266ab3eec44be26864323",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd",
      "unresolved": false
    }
  ]
}