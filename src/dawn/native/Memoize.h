// Copyright 2022 The Dawn Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <variant>

#include <utility>

#include "dawn/common/Preprocessor.h"
#include "dawn/common/Result.h"
#include "dawn/native/BlobCache.h"
#include "dawn/native/CacheKey.h"

#ifndef SRC_DAWN_NATIVE_MEMOIZE_H_
#define SRC_DAWN_NATIVE_MEMOIZE_H_

namespace dawn::native {

namespace detail {
// MemoResultTraits should be specialized for types T where
// T is the result of a cacheable computation. This class should not be used directly, but is
// used to customize the implementation of detail::MemoResult<T>.
template <typename T, typename SFINAE = void>
struct MemoResultTraits {
    // Implementations should define this static method for converting |T| into some Blob.
    // where |Blob| has methods `Blob::SizeInBytes()` and `Blob::Data()`;
    // The return type of SizeInBytes should be safely convertible to `size_t`, and the return
    // type of Data should be convertible to `const void*`.
    // This blob only needs to live from the time the memo result was computed, till the end
    // of Memoize(...);
    static auto AsBlob(const T& value);

    // Implementations should define these static methods to create a View which provides
    // an identical interface for reading data - regardless of whether the backing storage is
    // |T| or |CachedBlob|. The return type of both these functions should be identical.
    static auto View(T value);
    static auto View(CachedBlob blob);
};

// A MemoResult is a tagged union of type T and CachedBlob which is read/written
// to the BlobCache.
// MemoResult is only read by moving it into a "view". The view provides an interface to read
// data out of the result, either if the backing storage is T or if it is a CachedBlob.
// It may be converted to CachedBlob for storage into the BlobCache.
// MemoResultTraits should be specialized for each type. It provides the implementation
// of the view, and the conversion from T to CachedBlob.
template <typename T>
class MemoResult {
    using Traits = MemoResultTraits<T>;

  public:
    MemoResult(const MemoResult& other) = delete;
    MemoResult& operator=(const MemoResult& other) = delete;

    MemoResult(MemoResult&& other) = default;
    MemoResult& operator=(MemoResult&& other) = default;

    explicit constexpr MemoResult(T value) : data(std::move(value)) {}
    explicit MemoResult(CachedBlob s) : data(std::move(s)) {}
    ~MemoResult() = default;

    constexpr auto AsBlob() const { return Traits::AsBlob(std::get<T>(data)); }

    constexpr auto IntoView() && {
        return std::visit([](auto val) { return Traits::View(std::move(val)); }, std::move(data));
    }

  private:
    std::variant<T, CachedBlob> data;
};

}  // namespace detail

template <typename Fn, typename R, typename... Args>
struct MemoizeImpl;

template <typename T>
struct MemoizeArgForCacheKey {
    auto operator()(const T& value) { return value; }
};

// LogSink is ignored in the cache key since it only outputs logs and shouldn't
// impact the result of a memoized computation.
template <>
struct MemoizeArgForCacheKey<class LogSink> {
    auto operator()(const LogSink& value) { return CacheKey::IgnoredValue{}; }
};

// Memoize is a helper function which loads a result from the BlobCache, or creates it by
// calling |fn| if it was not available. Finally, the created result is stored back into |cache|.
//
// |fn| is static_assert'ed to be convertible to a plain-old function pointer.
// If it is a lambda, it means it has nothing bound to it. This is intended so that strictly the
// arguments into |Memoize| are used in the |fn|, so every input to it becomes part of the key.
//
// The key is generated from the device isolation key, every input argument, as well as a
// CacheKey::Type to uniquely identify this function signature. It would be better if the type enum
// could be autogenerated.
// Creating the key requires that every argument is serializable into the CacheKey. Arguments
// that should be skipped may be wrapped using |UnsafeUnkeyedValue|, but this is discouraged.
// Other arguments like |LogSink| may be determined "safe to skip serialization" if they are
// used strictly for output and will not affect the computation. |MemoizeArgForCacheKey| may be
// specialized for these safe types.
//
//   Example Usage:
//     // Using lambda
//     Memoize(cache, CacheKey::Type::Foo, [](int a, int b) {
//       return a + b;
//     }, 2, 3);
//
//     // Using a free function
//     int ExpensiveAdd(int a, int b);
//     Memoize(cache, CacheKey::Type::Foo, ExpensiveAdd, 2, 3);
//
template <typename Fn, typename... Args>
auto Memoize(BlobCache* cache,
             CacheKey::Type type,
             DeviceBase* device,
             Fn fn,
             const Args&... args) {
    // Deduce the return type.
    using R = decltype(fn(std::declval<const Args&>()...));
    static_assert(std::is_convertible_v<Fn, R (*)(Args...)>,
                  "Memoize function type does not match, or it is not a free function.");
    // Build a key from the device isolation key and arguments.
    CacheKey key = device->GetCacheKey();
    // Validate args, and filter out those that don't contribute to the cache key.
    key.Record(type, MemoizeArgForCacheKey<Args>{}(args)...);

    return MemoizeImpl<Fn, R, Args...>{}(cache, std::move(key), std::move(fn), args...);
}

// Specialization for MemoizeImpl when the return type is a ResultOrError
template <typename Fn, typename R, typename... Args>
struct MemoizeImpl<Fn, ResultOrError<R>, Args...> {
    ResultOrError<decltype(std::declval<detail::MemoResult<R>>().IntoView())>
    operator()(BlobCache* cache, CacheKey key, Fn fn, Args... args) {
        // Load the result from the cache.
        CachedBlob cachedBlob = cache->Load(key);
        if (!cachedBlob.Empty()) {
            // If we hit the cache, return it immediately.
            auto result = detail::MemoResult<R>(std::move(cachedBlob));
            return std::move(result).IntoView();
        }
        // Otherwise, call the functor to generate the result, wrapping it as a MemoResult.
        R successValue;
        DAWN_TRY_ASSIGN(successValue, fn(std::forward<Args>(args)...));
        auto result = detail::MemoResult<R>(std::move(successValue));
        // Store the result.
        auto storedBlob = result.AsBlob();
        cache->Store(key, storedBlob.SizeInBytes(), storedBlob.Data());
        return std::move(result).IntoView();
    }
};

}  // namespace dawn::native

#define DAWN_MEMOIZE_MAKE_ARG_INTERNAL(typeAndName, value) typeAndName
#define DAWN_MEMOIZE_GET_ARG_VALUE_INTERNAL(typeAndName, value) value

// Heleprs to get the argument declaration, or the argument value from a (type name, value) tuple.
#define DAWN_MEMOIZE_MAKE_ARG(tuple) DAWN_MEMOIZE_MAKE_ARG_INTERNAL tuple,
#define DAWN_MEMOIZE_GET_ARG_VALUE(tuple) DAWN_MEMOIZE_GET_ARG_VALUE_INTERNAL tuple,

// Same as DAWN_PP_FOR_EACH but leaves out the last arg which is the lambda body. It does
// it by prepending an unused argment, but keeping N, the number of arguments the same.
#define DAWN_MEMOIZE_FOR_EACH_ARG(func, ...) \
    DAWN_PP_FOR_EACH_(DAWN_PP_NARG(__VA_ARGS__), func, (int, 0), __VA_ARGS__)

// Helper macro for calling Memoize to avoid specifying the memo argument types and the memo inputs
// in two separate places. Instead, inputs and their types can be specified in a single place as a
// list of tuples. The macro will generate a lambda function with the input types, and pass the
// lambda to Memoize with the input values.
//   Example usage:
//     DAWN_MEMOIZE(cache, CacheKey::Type::Shader,
//       (int a, 2),
//       (int b, 3),
//       -> int {
//           return a + b;
//       })
#define DAWN_MEMOIZE(cache, type, device, ...)                                                    \
    /* __VA_ARGS__ is tuples of (type name, value), followed by the lambda body */                \
    Memoize(cache, type, device,                                                                  \
            [](/* Unpack the argument tuples to declare the lambda arguments.                     \
                  Should transform to: int, int a, float b, int                                   \
                  DAWN_MEMOIZE_FOR_EACH_ARG inserts a leading `int` arg so we can ignore the      \
                  lambda body in the __VA_ARGS__ list.                                            \
                  DAWN_MEMOIZE_MAKE_ARG uses a trailing commas after each arg, so a final `int`   \
                  unused argument is added so there are no trailing commas.                       \
               */                                                                                 \
               DAWN_PP_EXPAND(DAWN_MEMOIZE_FOR_EACH_ARG)(DAWN_MEMOIZE_MAKE_ARG, __VA_ARGS__) int) \
                                                                                                  \
            /* Get the tail which should be the brace-enclosed function body */                   \
            DAWN_PP_GET_TAIL(__VA_ARGS__),                                                        \
                                                                                                  \
            /* Unpack the argment tuples to pass in values for the lambda arguments */            \
            DAWN_PP_EXPAND(DAWN_MEMOIZE_FOR_EACH_ARG)(DAWN_MEMOIZE_GET_ARG_VALUE,                 \
                                                      __VA_ARGS__) /* trailing unused int */ 0)

#endif  // SRC_DAWN_NATIVE_MEMOIZE_H_
