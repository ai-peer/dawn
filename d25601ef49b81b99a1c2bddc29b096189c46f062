{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "26882d09_b2375f23",
        "filename": "src/dawn/native/EventManager.cpp",
        "patchSetId": 19
      },
      "lineNbr": 153,
      "author": {
        "id": 1002831
      },
      "writtenOn": "2023-11-21T21:20:26Z",
      "side": 1,
      "message": "nit. based on the waiting device and type of wait required.\n\n(The partition on device comment from before is lost otherwise, and it was not immediately obvious that that\u0027s what this was doing.)\n\nBut also, IIUC, this is now a O(n^2) operation since we might run `std::partition` n times, whereas the previous sort/splice version was O((n log n) + n) only. Maybe not a huge deal, but I\u0027m not sure why it was necessary to change that.",
      "range": {
        "startLine": 153,
        "startChar": 4,
        "endLine": 153,
        "endChar": 92
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9c8e644c_d95106b1",
        "filename": "src/dawn/native/EventManager.cpp",
        "patchSetId": 19
      },
      "lineNbr": 153,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2023-11-21T21:41:06Z",
      "side": 1,
      "message": "well, it depends... because we call std::partition on a smaller and smaller slice each time. - which is how quicksort works! pick a pivot, partition, pick a pivot, partition, pick a pivot, partition...\nso it should be O(n lg n) as well, but in the common case faster because:\n 1. we should do the partition fewer times than a full sort. At most k times where k is the number of queues, and k \u003c\u003d n.\n 2. we recurse using partition on just one side of the partition, whereas quicksort would recurse on both sides of the partition\n\nboth quicksort and this algorithm we use have a worst-case performance of O(n^2) due to unlucky/bad pivot selection. For us, this would happen when all futures come from a different queue. That said, idk if we need to optimize for a large number of queues (yet?)",
      "parentUuid": "26882d09_b2375f23",
      "range": {
        "startLine": 153,
        "startChar": 4,
        "endLine": 153,
        "endChar": 92
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "fa3a3b9f_6115a819",
        "filename": "src/dawn/native/EventManager.cpp",
        "patchSetId": 19
      },
      "lineNbr": 153,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2023-11-21T21:49:40Z",
      "side": 1,
      "message": "Even with multi-queue I think k is going to be the number of \"sources\" (devices, plus 1 for OS events), not queues. On Vulkan, this would usually be 1, and very rarely more than 2.\n\nOn Mac and Windows, everything is an OS event, so k can always be 1, although I don\u0027t think we\u0027re optimizing to take advantage of that yet.",
      "parentUuid": "26882d09_b2375f23",
      "range": {
        "startLine": 153,
        "startChar": 4,
        "endLine": 153,
        "endChar": 92
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b56a1727_df28dfd0",
        "filename": "src/dawn/native/EventManager.cpp",
        "patchSetId": 19
      },
      "lineNbr": 153,
      "author": {
        "id": 1002831
      },
      "writtenOn": "2023-11-21T21:57:44Z",
      "side": 1,
      "message": "Acknowledged",
      "parentUuid": "fa3a3b9f_6115a819",
      "range": {
        "startLine": 153,
        "startChar": 4,
        "endLine": 153,
        "endChar": 92
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e2ddf43a_6a53c7a8",
        "filename": "src/dawn/native/SystemEvent.h",
        "patchSetId": 19
      },
      "lineNbr": 115,
      "author": {
        "id": 1002831
      },
      "writtenOn": "2023-11-21T21:20:26Z",
      "side": 1,
      "message": "nit. I\u0027m wondering whether this should just be something like:\n\n```\nstruct SystemEventImpl {\n  bool mSignaled \u003d false;\n  std::optional\u003cstd::pair\u003cSender, Receiver\u003e\u003e mPipe;\n};\n\nMutexProtected\u003cSystemEventImpl\u003e impl;\n```\n\nThis might be more explicit about the locking since either way we need to acquire the lock when modifying the bool.",
      "range": {
        "startLine": 114,
        "startChar": 4,
        "endLine": 115,
        "endChar": 95
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c0cf660e_6a791327",
        "filename": "src/dawn/native/SystemEvent.h",
        "patchSetId": 19
      },
      "lineNbr": 115,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2023-11-21T21:41:06Z",
      "side": 1,
      "message": "I think the tricky bit is that Signal only acquires the lock the first time when it transitions from false to true. After that, it doesn\u0027t - which I think is reason enough to encapsulate this.\n\nAlso we will use SystemEvent again in the future to implement async pipeline creation.",
      "parentUuid": "e2ddf43a_6a53c7a8",
      "range": {
        "startLine": 114,
        "startChar": 4,
        "endLine": 115,
        "endChar": 95
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e7f4c65f_a134e98e",
        "filename": "src/dawn/native/SystemEvent.h",
        "patchSetId": 19
      },
      "lineNbr": 115,
      "author": {
        "id": 1002831
      },
      "writtenOn": "2023-11-21T21:57:44Z",
      "side": 1,
      "message": "Hmm I guess the question in that case is how often `Signal` would be called? I was under the impression that it should only really be called once? In which case there\u0027s no reason to bother optimizing for multiple `Signal` calls?",
      "parentUuid": "c0cf660e_6a791327",
      "range": {
        "startLine": 114,
        "startChar": 4,
        "endLine": 115,
        "endChar": 95
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5f6619b6_bed9afcf",
        "filename": "src/dawn/native/SystemEvent.h",
        "patchSetId": 19
      },
      "lineNbr": 115,
      "author": {
        "id": 1000032
      },
      "writtenOn": "2023-11-21T22:02:44Z",
      "side": 1,
      "message": "[1] and [2]. I guess it\u0027s not super frequent, but idk.. I still quite like to have the abstraction?\n\nyou could imagine we can optimize GetOrCreateSystemEventReceiver to not take the lock either by storing an atomic pointer to the receiver once it has been created - and that gets called more frequently in WaitAnySystemEventImpl",
      "parentUuid": "e7f4c65f_a134e98e",
      "range": {
        "startLine": 114,
        "startChar": 4,
        "endLine": 115,
        "endChar": 95
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c6ebfbd0_fc5b9cd2",
        "filename": "src/dawn/native/SystemEvent.h",
        "patchSetId": 19
      },
      "lineNbr": 115,
      "author": {
        "id": 1002831
      },
      "writtenOn": "2023-11-21T22:09:07Z",
      "side": 1,
      "message": "Hmm, ok I\u0027m fine with it either way, but the additional synchronization between the bool and the pipe just makes more overhead for maintenance and understanding what\u0027s happening, especially if the frequency of the path is small and locking doesn\u0027t incur too much additional performance cost.\n\nOtherwise, if leaving as is, I would suggest to add a comment above the members to document a bit why they are separated but are actually used with one another in some cases.",
      "parentUuid": "5f6619b6_bed9afcf",
      "range": {
        "startLine": 114,
        "startChar": 4,
        "endLine": 115,
        "endChar": 95
      },
      "revId": "d25601ef49b81b99a1c2bddc29b096189c46f062",
      "serverId": "dd02978d-1a8e-36d7-bcc0-a5723e5c0abd"
    }
  ]
}